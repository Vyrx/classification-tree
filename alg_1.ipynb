{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import queue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_x_loc = 'data_1\\\\train\\X_train.xlsx'\n",
    "train_file_y_loc = 'data_1\\\\train\\y_train.xlsx'\n",
    "test_file_loc = 'data_1\\Dataset1_test\\X_test.xlsx'\n",
    "\n",
    "train_data_x = pd.read_excel(train_file_x_loc)\n",
    "train_data_y = pd.read_excel(train_file_y_loc)\n",
    "test_data = pd.read_excel(test_file_loc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x = train_data_x.values\n",
    "tr_y = [i[0] for i in train_data_y.values]\n",
    "test = test_data.values\n",
    "num_features = len(tr_x[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_f in range(len(tr_x[0])):\n",
    "\n",
    "    temp = [x for x in tr_x[:,cur_f] if np.isnan(x) == False]\n",
    "    feature_mean = np.mean(temp)\n",
    "\n",
    "    for i in range(len(tr_x)):\n",
    "        if np.isnan(tr_x[i][cur_f]):\n",
    "            tr_x[i][cur_f] = feature_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy calculating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [3,4,5,6,7,8]\n",
    "\n",
    "count = np.bincount(tr_y)[3:]\n",
    "\n",
    "# Take bin count of each label value as input\n",
    "def get_entropy(count):\n",
    "    num_data = np.sum(count)\n",
    "    total = 0\n",
    "\n",
    "    for i in count:\n",
    "        prob = i / num_data\n",
    "        if prob == 0:\n",
    "            continue\n",
    "        total += prob * np.log2(prob)\n",
    "\n",
    "    return -total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class for the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.data = None    # Feature values, including labels\n",
    "        self.f_in = None    # The index of the traversal criteria\n",
    "        self.thresh = None  # The value threshold of the traversal criteria\n",
    "        self.label = None   # Label with the max amount\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.data = data\n",
    "        self.f_in = None\n",
    "        self.thresh = None\n",
    "        self.label = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_data = tr_x\n",
    "temp = []\n",
    "\n",
    "# Append target feature to cur_data\n",
    "for i in range(len(cur_data)):\n",
    "    temp.append( np.append(cur_data[i],int(tr_y[i])) )\n",
    "cur_data = np.array(temp)\n",
    "\n",
    "root = Node(cur_data)\n",
    "cur_node = root\n",
    "\n",
    "q = queue.Queue() # A queue for processing nodes of the decision tree\n",
    "q.put(cur_node)\n",
    "\n",
    "\n",
    "# # # LOOP\n",
    "\n",
    "while q.empty() == False:\n",
    "\n",
    "    cur_node = q.get()\n",
    "    cur_data = cur_node.data\n",
    "\n",
    "    # If data length is 0, continue\n",
    "    if len(cur_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    cur_label = [int(temp) for temp in cur_data[:,num_features]]\n",
    "    temp_count = np.bincount(cur_label)[3:]\n",
    "\n",
    "    # Assign the selected label to the current node\n",
    "    cur_node.label = np.argmax(temp_count) + 3\n",
    "\n",
    "    # If all data has the same label, stop\n",
    "    areAllLabelSame = False\n",
    "\n",
    "    for temp in temp_count:\n",
    "        if temp == sum(temp_count):\n",
    "            areAllLabelSame = True\n",
    "            break\n",
    "    if areAllLabelSame:\n",
    "        continue\n",
    "\n",
    "    # We want to get (feature, val) that minimizes IG\n",
    "    split_feat_in = 0 \n",
    "    split_thresh = 0\n",
    "    min_ent = np.Inf\n",
    "\n",
    "    # Go through each feature, sort the values\n",
    "    # i = current feature index\n",
    "    for i in range(num_features):  # range(num_features)\n",
    "        cur_feat_val = np.sort(cur_data[:,i])\n",
    "\n",
    "        # Iterate through each sorted value \n",
    "        for j in range(len(cur_feat_val) - 1):\n",
    "\n",
    "            # Get every unique feature values\n",
    "            if (cur_feat_val[j] !=  cur_feat_val[j+1]):\n",
    "                cur_thresh = cur_feat_val[j]\n",
    "\n",
    "                # Split data into two based on cur_thresh, get two labels\n",
    "                label1 = []\n",
    "                label2 = []\n",
    "                for temp_dat in cur_data:\n",
    "                    if temp_dat[i] <= cur_thresh:\n",
    "                        label1.append(int(temp_dat[num_features])) # Append the label\n",
    "                    else:\n",
    "                        label2.append(int(temp_dat[num_features]))\n",
    "                \n",
    "                label1 = np.array(label1)\n",
    "                label2 = np.array(label2)\n",
    "\n",
    "                count1 = np.bincount(label1)[3:]\n",
    "                count2 = np.bincount(label2)[3:]\n",
    "\n",
    "                num_labels_1 = np.sum(count1)\n",
    "                num_labels_2 = np.sum(count2)\n",
    "\n",
    "                w_avg_ent = (num_labels_1 / (num_labels_1 + num_labels_2)) * get_entropy(count1) + (num_labels_2 / (num_labels_1 + num_labels_2)) * get_entropy(count2)\n",
    "                \n",
    "                # Maximizing IG == minimizing w_avg_ent\n",
    "\n",
    "                if w_avg_ent < min_ent:\n",
    "                    min_ent = w_avg_ent\n",
    "                    split_feat_in = i\n",
    "                    split_thresh = cur_thresh\n",
    "    \n",
    "    # Split data into two\n",
    "    data_left = []\n",
    "    data_right = []\n",
    "\n",
    "    # For each data put in either left / right\n",
    "    for temp_dat in cur_data:\n",
    "        if temp_dat[split_feat_in] <= split_thresh:\n",
    "            data_left.append(temp_dat)\n",
    "        else:\n",
    "            data_right.append(temp_dat)\n",
    "    \n",
    "    data_left = np.array(data_left)\n",
    "    data_right = np.array(data_right)\n",
    "\n",
    "\n",
    "    # Update data structure\n",
    "    cur_node.thresh = split_thresh\n",
    "    cur_node.f_in = split_feat_in\n",
    "\n",
    "    cur_node.left = Node(data_left)\n",
    "    cur_node.right = Node(data_right)\n",
    "\n",
    "    q.put(cur_node.left)\n",
    "    q.put(cur_node.right)\n",
    "\n",
    "    #print(cur_node.thresh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Performance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Input: \n",
      "[[9.10e+00 7.65e-01 4.00e-02 ... 3.29e+00 5.40e-01 9.70e+00]\n",
      " [6.90e+00 7.40e-01      nan ...      nan 6.30e-01 1.15e+01]\n",
      " [     nan 5.80e-01 2.30e-01 ... 3.21e+00 5.80e-01 9.50e+00]\n",
      " ...\n",
      " [9.00e+00 5.80e-01 2.50e-01 ... 3.23e+00 5.70e-01 9.70e+00]\n",
      " [8.30e+00 8.45e-01 1.00e-02 ... 3.32e+00 5.80e-01 1.10e+01]\n",
      " [8.60e+00 6.30e-01 1.70e-01 ... 3.09e+00 5.20e-01 9.30e+00]]\n"
     ]
    }
   ],
   "source": [
    "print('Test Input: ')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_f in range(len(test[0])):\n",
    "\n",
    "    temp = [x for x in test[:,cur_f] if np.isnan(x) == False]\n",
    "    feature_mean = np.mean(temp)\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        if np.isnan(test[i][cur_f]):\n",
    "            test[i][cur_f] = feature_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     class\n",
      "0        6\n",
      "1        6\n",
      "2        6\n",
      "3        5\n",
      "4        5\n",
      "..     ...\n",
      "251      5\n",
      "252      6\n",
      "253      5\n",
      "254      5\n",
      "255      5\n",
      "\n",
      "[256 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "pred_label = []\n",
    "\n",
    "for item in test:\n",
    "    cur_node = root\n",
    "    while True:\n",
    "        if cur_node.left == None or cur_node.right == None:\n",
    "            pred_label.append(cur_node.label)\n",
    "            break\n",
    "\n",
    "        if item[cur_node.f_in] <= cur_node.thresh:\n",
    "            cur_node = cur_node.left\n",
    "        else: \n",
    "            cur_node = cur_node.right\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "pred_label = np.array(pred_label)\n",
    "\n",
    "d = pd.DataFrame({'class': pred_label})\n",
    "df = pd.DataFrame(data=d)\n",
    "df.to_excel('out_1.xlsx',index=False)\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
